{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 01: Use of CELLxGENE**\n",
    "\n",
    "Ray LeClair \\<2024-07-01 Mon\\>\n",
    "\n",
    "# Objectives\n",
    "\n",
    "Since CELLxGENE serves as an initiating data source for the NCBI Cell\n",
    "pilot, the objectives of this document include demonstration of:\n",
    "\n",
    "-   Identification of CELLxGENE datasets for a particular organism, and\n",
    "    tissue\n",
    "\n",
    "-   Identification of publications corresponding to CELLxGENE datasets\n",
    "\n",
    "-   Determination of the dataset filename and dataset file download.\n",
    "\n",
    "## Background\n",
    "\n",
    "All single-cell RNA data from Chan Zuckerberg (CZ) CELLxGENE Discover\n",
    "is accessed, queried, and analyzed using the CELLxGENE Discover\n",
    "Census. Using cell-based slicing and querying one can:\n",
    "\n",
    "-   Interact with the data through TileDB-SOMA\n",
    "\n",
    "-   Get slices in AnnData, Seurat, or SingleCellExperiment objects\n",
    "\n",
    "See: [CELLxGENE Discover Census](https://chanzuckerberg.github.io/cellxgene-census/)\n",
    "\n",
    "The following sections draw from CZ CELLxGENE tutorials, or a Chan\n",
    "Zuckerberg Initiative (CZI) repository, which demonstrate how to:\n",
    "\n",
    "-   [Explore and query the Census in the context of a single tissue, lung](https://chanzuckerberg.github.io/cellxgene-census/notebooks/analysis_demo/comp_bio_explore_and_load_lung_data.html)\n",
    "\n",
    "-   [Query the expression data and cell/gene metadata from the Census, and load them into common in-memory Python objects](https://chanzuckerberg.github.io/cellxgene-census/notebooks/api_demo/census_query_extract.html)\n",
    "\n",
    "-   [Generate a citation string for all datasets contained in a Census slice](https://chanzuckerberg.github.io/cellxgene-census/notebooks/api_demo/census_citation_generation.html)\n",
    "\n",
    "-   [Fetch full metadata for a Dataset](https://github.com/chanzuckerberg/single-cell-curation/blob/0c77179d2e794846861f8109c037b723507959cb/notebooks/curation_api/python_raw/get_dataset.ipynb)\n",
    "\n",
    "## Development environment\n",
    "\n",
    "See: [Introduction.ipynb](Introduction.ipynb)\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "Launch Jupyter Notebook from a terminal in which `.zshenv` has been\n",
    "sourced, and the virtual environment has been activated.\n",
    "\n",
    "### Emacs Org Mode\n",
    "\n",
    "Launch Emacs from a terminal in which `.zshenv` has been sourced, then\n",
    "evaluate this code block to activate the virtual environment:\n",
    "\n",
    "``` commonlisp\n",
    "(pyvenv-activate \"../../.venv\")\n",
    "```\n",
    "\n",
    "# Identification of CELLxGENE datasets for human, lung cells\n",
    "\n",
    "Following the first tutorial, we write a function that obtains all\n",
    "human lung cell metadata and datasets from the CZ CELLxGENE Census as\n",
    "Pandas DataFrames. Anticipating a time consuming process, the first\n",
    "call of the function writes the DataFrames to `.parquet` files, then,\n",
    "on subsequent calls, it reads the `.parquet` files. In both cases, the\n",
    "resulting DataFrames are returned.\n",
    "\n",
    "To begin, we import modules, and assign module scope variables:"
   ],
   "id": "e283bd34-b7a6-4931-9b47-2dca35927b98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "silent",
    "session": "shared",
    "tangle": "../py/CELLxGENE.py"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "from traceback import print_exc\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "CELLXGENE_DOMAIN_NAME = \"cellxgene.cziscience.com\"\n",
    "CELLXGENE_API_URL_BASE = f\"https://api.{CELLXGENE_DOMAIN_NAME}\"\n",
    "CELLXGENE_DIR = f\"{DATA_DIR}/cellxgene\"\n",
    "\n",
    "NCBI_CELL_DIR = f\"{DATA_DIR}/ncbi-cell\"\n",
    "\n",
    "HTTPS_SLEEP = 1\n"
   ],
   "id": "8f5ddac4-fe81-4ac7-9aab-f9e312ac4d1d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we write the function:"
   ],
   "id": "89cf701c-4493-47a6-9820-a21fc30775a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "silent",
    "session": "shared",
    "tangle": "../py/CELLxGENE.py"
   },
   "outputs": [],
   "source": [
    "def get_lung_obs_and_datasets():\n",
    "    \"\"\"Use the CZ CELLxGENE Census to obtain all unprocessed human\n",
    "    lung cell metadata and datasets, then write the resulting Pandas\n",
    "    DataFrames to parquet files, or, if the files exist, read them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lung_obs : pd.DataFrame\n",
    "        DataFrame containing unprocessed dataset metadata\n",
    "    lung_datasets : pd.DataFrame\n",
    "        DataFrame containing unprocessed dataset descriptions\n",
    "    \"\"\"\n",
    "    # Create and write, or read DataFrames\n",
    "    lung_obs_parquet = f\"{NCBI_CELL_DIR}/up_lung_obs.parquet\"\n",
    "    lung_datasets_parquet = f\"{NCBI_CELL_DIR}/up_lung_datasets.parquet\"\n",
    "    if not os.path.exists(lung_obs_parquet) or not os.path.exists(\n",
    "             lung_datasets_parquet\n",
    "    ):\n",
    "        print(\"Opening soma\")\n",
    "        census = cellxgene_census.open_soma(census_version=\"latest\")\n",
    "\n",
    "        print(\"Collecting all datasets\")\n",
    "        datasets = census[\"census_info\"][\"datasets\"].read().concat().to_pandas()\n",
    "\n",
    "        print(\"Collecting lung obs\")\n",
    "        lung_obs = (\n",
    "            census[\"census_data\"][\"homo_sapiens\"]\n",
    "            .obs.read(\n",
    "                value_filter=\"tissue_general == 'lung' and is_primary_data == True\"\n",
    "            )\n",
    "            .concat()\n",
    "            .to_pandas()\n",
    "        )\n",
    "\n",
    "        print(\"Closing soma\")\n",
    "        census.close()\n",
    "\n",
    "        print(\"Writing unprocessed lung obs parquet\")\n",
    "        lung_obs.to_parquet(lung_obs_parquet)\n",
    "\n",
    "        print(\"Finding unprocessed lung datasets\")\n",
    "        lung_datasets = datasets[datasets[\"dataset_id\"].isin(lung_obs[\"dataset_id\"])]\n",
    "\n",
    "        print(\"Writing unprocessed lung datasets parquet\")\n",
    "        lung_datasets.to_parquet(lung_datasets_parquet)\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"Reading unprocessed lung obs parquet\")\n",
    "        lung_obs = pd.read_parquet(lung_obs_parquet)\n",
    "\n",
    "        print(\"Reading unprocessed lung datasets parquet\")\n",
    "        lung_datasets = pd.read_parquet(lung_datasets_parquet)\n",
    "\n",
    "    return lung_obs, lung_datasets\n"
   ],
   "id": "d6367acb-b237-405d-8464-8d2f38692640"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call it to obtain the human lung cell metadata and datasets\n",
    "(using exception handling since accessing an external resource), and\n",
    "print the result:"
   ],
   "id": "f3d95b6c-f39f-4009-8994-44e0df379b6a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    lung_obs, lung_datasets = get_lung_obs_and_datasets()\n",
    "except Exception:\n",
    "    print_exc()\n",
    "print(f\"lung_obs:\\n\\ncolumns: {lung_obs.columns}\\n\\n{lung_obs}\")\n",
    "print()\n",
    "print(f\"lung_datasets:\\n\\ncolumns: {lung_datasets.columns}\\n\\n{lung_datasets}\")\n"
   ],
   "id": "f626f953-def8-442a-a9d1-6aa21f41fde4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of publications corresponding to CELLxGENE datasets\n",
    "\n",
    "We notice that the datasets DataFrame contains a `citation` column,\n",
    "for example:"
   ],
   "id": "a8b983bd-ccfc-4a96-988e-49496bc4b915"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "print(lung_datasets[\"citation\"].iloc[4])\n"
   ],
   "id": "5f60a380-d714-4e4a-b2c0-e989e7d843cf"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `citation` provides the DOI, but not the title of the\n",
    "publication. Note that we will need the title later in Chapter 02:\n",
    "E-Utilities. So, we examine the `collection_name` and `dataset_title`\n",
    "columns:\n",
    "\n",
    "See: [Chapter-02-E-Utilities.ipynb](Chapter-02-E-Utilities.ipynb)"
   ],
   "id": "7f2724b4-0254-429d-beb3-46cb1bb3b56e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "print(lung_datasets[[\"collection_name\", \"dataset_title\"]].iloc[4, :])\n"
   ],
   "id": "ecf4b555-99ed-4260-97bb-864631eb3ad8"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it appears we still need to find the title by some method. So, we\n",
    "write a function that requests the DOI, then parses the resulting\n",
    "page, most likely from the publisher, to find the title."
   ],
   "id": "71e9ff02-ae6f-43d2-beaa-ee6690a4fdd6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "silent",
    "session": "shared",
    "tangle": "../py/CELLxGENE.py"
   },
   "outputs": [],
   "source": [
    "def get_title(citation):\n",
    "    \"\"\"Get the title given a dataset citation. Note that only wget\n",
    "    succeeded for Cell Press journals, and neither requests nor wget\n",
    "    succeeded for The EMBO Journal and Science.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    citation : str\n",
    "        Dataset citation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    title : str\n",
    "        Title of publication associated with the dataset\n",
    "    \"\"\"\n",
    "    # Need a default return value\n",
    "    title = None\n",
    "\n",
    "    # Compile patterns for finding the publication URL and article\n",
    "    # title\n",
    "    p1 = re.compile(\"Publication: (.*) Dataset Version:\")\n",
    "    p2 = re.compile(\"articleName : '(.*)',\")\n",
    "\n",
    "    # Assign CSS selectors for selecting article title elements\n",
    "    selectors = [\n",
    "        \"h1.c-article-title\",\n",
    "        \"h1.article-header__title.smaller\",\n",
    "        \"div.core-container h1\",\n",
    "        \"h1.content-header__title.content-header__title--xx-long\",\n",
    "        \"h1#page-title.highwire-cite-title\",\n",
    "    ]\n",
    "\n",
    "    # Find the publication URL\n",
    "    m1 = p1.search(citation)\n",
    "    if not m1:\n",
    "        logging.warning(f\"Could not find citation URL for {citation}\")\n",
    "        return title\n",
    "    citation_url = m1.group(1)\n",
    "    print(f\"Getting title for citation URL: {citation_url}\")\n",
    "\n",
    "    # Attempt to get the publication page using requests\n",
    "    print(f\"Trying requests\")\n",
    "    sleep(HTTPS_SLEEP)\n",
    "    response = requests.get(citation_url)\n",
    "    try_wget = True\n",
    "    if response.status_code == 200:\n",
    "        html_data = response.text\n",
    "\n",
    "        # Got the page, so parse it, and try each selector\n",
    "        fullsoup = BeautifulSoup(html_data, features=\"lxml\")\n",
    "        for selector in selectors:\n",
    "            selected = fullsoup.select(selector)\n",
    "            if selected:\n",
    "\n",
    "                # Selected the article title, so assign it\n",
    "                if len(selected) > 1:\n",
    "                    logging.warning(\n",
    "                        f\"Selected more than one element using {selector} on soup from {citation_url}\"\n",
    "                    )\n",
    "                title = selected[0].text\n",
    "                try_wget = False\n",
    "                break\n",
    "\n",
    "    if try_wget:\n",
    "\n",
    "        # Attempt to get the publication page using wget\n",
    "        print(f\"Trying wget\")\n",
    "        sleep(HTTPS_SLEEP)\n",
    "        completed_process = subprocess.run(\n",
    "            [\"curl\", \"-L\", citation_url], capture_output=True\n",
    "        )\n",
    "        html_data = completed_process.stdout\n",
    "\n",
    "        # Got the page, so parse it, and search for the title\n",
    "        fullsoup = BeautifulSoup(html_data, features=\"lxml\")\n",
    "        found = fullsoup.find_all(\"script\")\n",
    "        if found and len(found) > 4:\n",
    "            m2 = p2.search(found[4].text)\n",
    "            if m2:\n",
    "                title = m2.group(1)\n",
    "\n",
    "    print(f\"Found title: '{title}' for citation URL: {citation_url}\")\n",
    "\n",
    "    return title\n"
   ],
   "id": "2c81b662-bf95-4470-91bf-382e450bdfac"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we call the function for an example citation (again using\n",
    "exception handling since accessing an external resource):"
   ],
   "id": "bbc8c569-294d-46cc-85f8-ad76f6eb652c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    citation = lung_datasets[\"citation\"].iloc[0]\n",
    "    title = get_title(citation)\n",
    "except Exception:\n",
    "    print_exc()\n"
   ],
   "id": "68858ff1-5b7e-4113-b0e1-bd76b0302381"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the function attempts to use `requests`, and if it fails,\n",
    "`wget`, since some publishers respond to one, but not the other. The\n",
    "selectors were discovered by manually inspecting the pages returned\n",
    "for the human lung cell datasets using Google Chrome Developer Tools.\n",
    "\n",
    "# Determine the dataset filename and download the dataset file.\n",
    "\n",
    "Following a notebook found in a CZI repository, we write a function to\n",
    "find the dataset filename, and to download the dataset file, given a\n",
    "row of the datasets DataFrame obtained above:"
   ],
   "id": "712fba84-ac2e-4da3-9691-fbf141d720cc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "silent",
    "session": "shared",
    "tangle": "../py/CELLxGENE.py"
   },
   "outputs": [],
   "source": [
    "def get_and_download_dataset_h5ad_file(dataset_series):\n",
    "    \"\"\"Get the dataset filename and download the dataset file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_series : pd.Series\n",
    "        A row from the dataset DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataset : str\n",
    "       The dataset filename\n",
    "    \"\"\"\n",
    "    # Need a default return value\n",
    "    dataset_filename = None\n",
    "\n",
    "    # Get the dataset object\n",
    "    collection_id = dataset_series.collection_id\n",
    "    dataset_id = dataset_series.dataset_id\n",
    "    dataset_url = f\"{CELLXGENE_API_URL_BASE}/curation/v1/collections/{collection_id}/datasets/{dataset_id}\"\n",
    "    sleep(HTTPS_SLEEP)\n",
    "    response = requests.get(dataset_url)\n",
    "    response.raise_for_status()\n",
    "    if response.status_code != 200:\n",
    "        logging.error(f\"Could not get dataset for id {dataset_id}\")\n",
    "        return\n",
    "\n",
    "    data = response.json()\n",
    "    if dataset_id != data[\"dataset_id\"]:\n",
    "        logging.error(\n",
    "            f\"Response dataset id: {data['dataset_id']} does not equal specified dataset id: {dataset_id}\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Find H5AD files, if possible\n",
    "    assets = data[\"assets\"]\n",
    "    for asset in assets:\n",
    "        if asset[\"filetype\"] != \"H5AD\":\n",
    "            continue\n",
    "\n",
    "        # Found an H5AD file, so download it, if needed\n",
    "        dataset_filename = f\"{dataset_id}.{asset['filetype']}\"\n",
    "        dataset_filepath = f\"{CELLXGENE_DIR}/{dataset_filename}\"\n",
    "        if not os.path.exists(dataset_filepath):\n",
    "            print(f\"Downloading dataset file: {dataset_filepath}\")\n",
    "            with requests.get(asset[\"url\"], stream=True) as response:\n",
    "                response.raise_for_status()\n",
    "                with open(dataset_filepath, \"wb\") as df:\n",
    "                    for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "                        df.write(chunk)\n",
    "            print(f\"Dataset file: {dataset_filepath} downloaded\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Dataset file: {dataset_filepath} exists\")\n",
    "\n",
    "    return dataset_filename\n"
   ],
   "id": "d56f5719-2bc4-4f59-88b2-5489ddd60739"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call it using the first row of the human lung cell datasets\n",
    "DataFrame obtained above, and print the result (we'll use exception\n",
    "handling when accessing an external resource from now on):"
   ],
   "id": "d2c5b280-8b8f-48bf-bb4a-76f8e8b3fa0c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset_series = lung_datasets.iloc[0]\n",
    "    get_and_download_dataset_h5ad_file(dataset_series)\n",
    "except Exception:\n",
    "    print_exc()\n"
   ],
   "id": "1221015c-b907-4813-abae-f74c7d6e034a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in Chapter 02 we write functions to search PubMed for the title\n",
    "and identifiers.\n",
    "\n",
    "See: [Chapter-02-E-Utilities.ipynb](Chapter-02-E-Utilities.ipynb)"
   ],
   "id": "bc071ea2-bdcb-4990-93d4-35df15abef4c"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
