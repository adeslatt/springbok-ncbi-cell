{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "Since CELLxGENE serves as an initiating data source for the NCBI Cell\n",
    "pilot, the objectives of this document include demonstration of:\n",
    "\n",
    "-   Identification of CELLxGENE datasets for a particular organism, and\n",
    "    tissue\n",
    "\n",
    "-   Identification of publications corresponding to CELLxGENE datasets\n",
    "\n",
    "-   Determination of the dataset filename and dataset file download.\n",
    "\n",
    "## Background\n",
    "\n",
    "All single-cell RNA data from Chan Zuckerberg (CZ) CELLxGENE Discover is\n",
    "accessed, queried, and analyzed using the [CELLxGENE Discover\n",
    "Census](https://chanzuckerberg.github.io/cellxgene-census/). Using\n",
    "cell-based slicing and querying one can:\n",
    "\n",
    "-   Interact with the data through TileDB-SOMA\n",
    "\n",
    "-   Get slices in AnnData, Seurat, or SingleCellExperiment objects\n",
    "\n",
    "The following sections draw from CZ CELLxGENE tutorials, or a Chan\n",
    "Zuckerberg Initiative (CZI) repository, which demonstrate how to:\n",
    "\n",
    "-   [Explore and query the Census in the context of a single tissue,\n",
    "    lung](https://chanzuckerberg.github.io/cellxgene-census/notebooks/analysis_demo/comp_bio_explore_and_load_lung_data.html)\n",
    "\n",
    "-   [Query the expression data and cell/gene metadata from the Census,\n",
    "    and load them into common in-memory Python\n",
    "    objects](https://chanzuckerberg.github.io/cellxgene-census/notebooks/api_demo/census_query_extract.html)\n",
    "\n",
    "-   [Generate a citation string for all datasets contained in a Census\n",
    "    slice](https://chanzuckerberg.github.io/cellxgene-census/notebooks/api_demo/census_citation_generation.html)\n",
    "\n",
    "-   [Fetch full metadata for a\n",
    "    Dataset](https://github.com/chanzuckerberg/single-cell-curation/blob/0c77179d2e794846861f8109c037b723507959cb/notebooks/curation_api/python_raw/get_dataset.ipynb)\n",
    "\n",
    "## Development environment\n",
    "\n",
    "See [Introduction.ipynb](Introduction.ipynb).\n",
    "\n",
    "### Jupyter Notebook\n",
    "\n",
    "Launch Jupyter Notebook from a terminal in which `.zshenv` has been\n",
    "sourced, and the virtual environment has been activated.\n",
    "\n",
    "### Emacs Org Mode\n",
    "\n",
    "Launch Emacs from a terminal in which `.zshenv` has been sourced, then\n",
    "evaluate this code block to activate the virtual environment:\n",
    "\n",
    "``` commonlisp\n",
    "(pyvenv-activate \"../../.venv\")\n",
    "```\n",
    "\n",
    "# Identification of CELLxGENE datasets for human, lung cells\n",
    "\n",
    "Following the first tutorial, we write a function that obtains all human\n",
    "lung cell metadata and datasets from the CZ CELLxGENE Census as Pandas\n",
    "DataFrames. Anticipating a time consuming process, the first call of the\n",
    "function writes the DataFrames to `.parquet` files, then, on subsequent\n",
    "calls, it reads the `.parquet` files. In both cases, the resulting\n",
    "DataFrames are returned.\n",
    "\n",
    "To begin, we import modules, and assign module scope variables:"
   ],
   "id": "3dc785c4-a7ff-4028-806b-3ec72834f53f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "silent",
    "session": "shared",
    "tangle": "../py/CELLxGENE.py"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "CELLXGENE_DOMAIN_NAME = \"cellxgene.cziscience.com\"\n",
    "CELLXGENE_API_URL_BASE = f\"https://api.{CELLXGENE_DOMAIN_NAME}\"\n",
    "CELLXGENE_DIR = f\"{DATA_DIR}/cellxgene\"\n",
    "\n",
    "NCBI_CELL_DIR = f\"{DATA_DIR}/ncbi-cell\"\n",
    "\n",
    "HTTPS_SLEEP = 1\n"
   ],
   "id": "8bd8bdfa-d7bf-4672-b1ba-7fbbfde81d6b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we write the function:"
   ],
   "id": "b5f80630-b73b-4380-9601-a0ae4e852fa5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "silent",
    "session": "shared",
    "tangle": "../py/CELLxGENE.py"
   },
   "outputs": [],
   "source": [
    "def get_lung_obs_and_datasets():\n",
    "    \"\"\"Use the CZ CELLxGENE Census to obtain all unprocessed human\n",
    "    lung cell metadata and datasets, then write the resulting Pandas\n",
    "    DataFrames to parquet files, or, if the files exist, read them.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lung_obs : pd.DataFrame\n",
    "        DataFrame containing unprocessed dataset metadata\n",
    "    lung_datasets : pd.DataFrame\n",
    "        DataFrame containing unprocessed dataset descriptions\n",
    "    \"\"\"\n",
    "    # Create and write, or read DataFrames\n",
    "    lung_obs_parquet = f\"{NCBI_CELL_DIR}/up_lung_obs.parquet\"\n",
    "    lung_datasets_parquet = f\"{NCBI_CELL_DIR}/up_lung_datasets.parquet\"\n",
    "    if not os.path.exists(lung_obs_parquet) or not os.path.exists(\n",
    "             lung_datasets_parquet\n",
    "    ):\n",
    "        print(\"Opening soma\")\n",
    "        census = cellxgene_census.open_soma(census_version=\"latest\")\n",
    "\n",
    "        print(\"Collecting all datasets\")\n",
    "        datasets = census[\"census_info\"][\"datasets\"].read().concat().to_pandas()\n",
    "\n",
    "        print(\"Collecting lung obs\")\n",
    "        lung_obs = (\n",
    "            census[\"census_data\"][\"homo_sapiens\"]\n",
    "            .obs.read(\n",
    "                value_filter=\"tissue_general == 'lung' and is_primary_data == True\"\n",
    "            )\n",
    "            .concat()\n",
    "            .to_pandas()\n",
    "        )\n",
    "\n",
    "        print(\"Closing soma\")\n",
    "        census.close()\n",
    "\n",
    "        print(\"Writing unprocessed lung obs parquet\")\n",
    "        lung_obs.to_parquet(lung_obs_parquet)\n",
    "\n",
    "        print(\"Finding unprocessed lung datasets\")\n",
    "        lung_datasets = datasets[datasets[\"dataset_id\"].isin(lung_obs[\"dataset_id\"])]\n",
    "\n",
    "        print(\"Writing unprocessed lung datasets parquet\")\n",
    "        lung_datasets.to_parquet(lung_datasets_parquet)\n",
    "\n",
    "    else:\n",
    "\n",
    "        print(\"Reading unprocessed lung obs parquet\")\n",
    "        lung_obs = pd.read_parquet(lung_obs_parquet)\n",
    "\n",
    "        print(\"Reading unprocessed lung datasets parquet\")\n",
    "        lung_datasets = pd.read_parquet(lung_datasets_parquet)\n",
    "\n",
    "    return lung_obs, lung_datasets\n"
   ],
   "id": "ebd0e2b2-b807-440a-8e74-63c55e48f0ee"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call it to obtain the human lung cell metadata and datasets (using\n",
    "exception handling since accessing an external resource), and print the\n",
    "result:"
   ],
   "id": "b013b15c-0219-47ab-9a44-5bd3f326ca93"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    lung_obs, lung_datasets = get_lung_obs_and_datasets()\n",
    "except Exception:\n",
    "    print_exc()\n",
    "print(f\"lung_obs:\\n\\ncolumns: {lung_obs.columns}\\n\\n{lung_obs}\")\n",
    "print()\n",
    "print(f\"lung_datasets:\\n\\ncolumns: {lung_datasets.columns}\\n\\n{lung_datasets}\")\n"
   ],
   "id": "37651771-c07a-4b1b-a370-4cd164e5fb35"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of publications corresponding to CELLxGENE datasets\n",
    "\n",
    "We notice that the datasets DataFrame contains a `citation` column, for\n",
    "example:"
   ],
   "id": "90299119-bd38-43f3-a8ca-68e77dfa440b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "print(lung_datasets[\"citation\"].iloc[4])\n"
   ],
   "id": "9f299266-178d-4831-8bc1-dc8f5c96eadb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `citation` provides the DOI, but not the title of the publication.\n",
    "Note that we will need the title later (see\n",
    "[Chapter-02-E-Utilities.ipynb](Chapter-02-E-Utilities.ipynb)). So, we\n",
    "examine the `collection_name` and `dataset_title` columns:"
   ],
   "id": "9132f4a9-0216-4c5a-9a61-df396bdf1a50"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "print(lung_datasets[[\"collection_name\", \"dataset_title\"]].iloc[4, :])\n"
   ],
   "id": "2cd3bd94-cdc8-400e-9eec-5ade689b8860"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it appears we still need to find the title by some method. So, we\n",
    "write a function that requests the DOI, then parses the resulting page,\n",
    "most likely from the publisher, to find the title."
   ],
   "id": "ed7031f9-e10e-49f8-b967-9d8ab72f695d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "silent",
    "session": "shared",
    "tangle": "../py/CELLxGENE.py"
   },
   "outputs": [],
   "source": [
    "def get_title(citation):\n",
    "    \"\"\"Get the title given a dataset citation. Note that only wget\n",
    "    succeeded for Cell Press journals, and neither requests nor wget\n",
    "    succeeded for The EMBO Journal and Science.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    citation : str\n",
    "        Dataset citation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    title : str\n",
    "        Title of publication associated with the dataset\n",
    "    \"\"\"\n",
    "    # Need a default return value\n",
    "    title = None\n",
    "\n",
    "    # Compile patterns for finding the publication URL and article\n",
    "    # title\n",
    "    p1 = re.compile(\"Publication: (.*) Dataset Version:\")\n",
    "    p2 = re.compile(\"articleName : '(.*)',\")\n",
    "\n",
    "    # Assign CSS selectors for selecting article title elements\n",
    "    selectors = [\n",
    "        \"h1.c-article-title\",\n",
    "        \"h1.article-header__title.smaller\",\n",
    "        \"div.core-container h1\",\n",
    "        \"h1.content-header__title.content-header__title--xx-long\",\n",
    "        \"h1#page-title.highwire-cite-title\",\n",
    "    ]\n",
    "\n",
    "    # Find the publication URL\n",
    "    m1 = p1.search(citation)\n",
    "    if not m1:\n",
    "        logging.warning(f\"Could not find citation URL for {citation}\")\n",
    "        return title\n",
    "    citation_url = m1.group(1)\n",
    "    print(f\"Getting title for citation URL: {citation_url}\")\n",
    "\n",
    "    # Attempt to get the publication page using requests\n",
    "    print(f\"Trying requests\")\n",
    "    sleep(HTTPS_SLEEP)\n",
    "    response = requests.get(citation_url)\n",
    "    try_wget = True\n",
    "    if response.status_code == 200:\n",
    "        html_data = response.text\n",
    "\n",
    "        # Got the page, so parse it, and try each selector\n",
    "        fullsoup = BeautifulSoup(html_data, features=\"lxml\")\n",
    "        for selector in selectors:\n",
    "            selected = fullsoup.select(selector)\n",
    "            if selected:\n",
    "\n",
    "                # Selected the article title, so assign it\n",
    "                if len(selected) > 1:\n",
    "                    logging.warning(\n",
    "                        f\"Selected more than one element using {selector} on soup from {citation_url}\"\n",
    "                    )\n",
    "                title = selected[0].text\n",
    "                try_wget = False\n",
    "                break\n",
    "\n",
    "    if try_wget:\n",
    "\n",
    "        # Attempt to get the publication page using wget\n",
    "        print(f\"Trying wget\")\n",
    "        sleep(HTTPS_SLEEP)\n",
    "        completed_process = subprocess.run(\n",
    "            [\"curl\", \"-L\", citation_url], capture_output=True\n",
    "        )\n",
    "        html_data = completed_process.stdout\n",
    "\n",
    "        # Got the page, so parse it, and search for the title\n",
    "        fullsoup = BeautifulSoup(html_data, features=\"lxml\")\n",
    "        found = fullsoup.find_all(\"script\")\n",
    "        if found and len(found) > 4:\n",
    "            m2 = p2.search(found[4].text)\n",
    "            if m2:\n",
    "                title = m2.group(1)\n",
    "\n",
    "    print(f\"Found title: '{title}' for citation URL: {citation_url}\")\n",
    "\n",
    "    return title\n"
   ],
   "id": "a99f74ac-241a-44d2-b81c-62427be587be"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we call the function for an example citation (again using exception\n",
    "handling since accessing an external resource):"
   ],
   "id": "40309f47-50ef-403f-83c2-80ff3e59b4e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    citation = lung_datasets[\"citation\"].iloc[0]\n",
    "    title = get_title(citation)\n",
    "except Exception:\n",
    "    print_exc()\n"
   ],
   "id": "f6a65b79-1d5e-4f94-85b9-b5b53df27b47"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the function attempts to use `requests`, and if it fails,\n",
    "`wget`, since some publishers respond to one, but not the other. The\n",
    "selectors were discovered by manually inspecting the pages returned for\n",
    "the human lung cell datasets using Google Chrome Developer Tools.\n",
    "\n",
    "# Determine the dataset filename and download the dataset file.\n",
    "\n",
    "Following a notebook found in a CZI repository, we write a function to\n",
    "find the dataset filename, and to download the dataset file, given a row\n",
    "of the datasets DataFrame obtained above:"
   ],
   "id": "39bd3155-23ba-4456-bd8b-45aad92164aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "silent",
    "session": "shared",
    "tangle": "../py/CELLxGENE.py"
   },
   "outputs": [],
   "source": [
    "def get_and_download_dataset_h5ad_file(dataset_series):\n",
    "    \"\"\"Get the dataset filename and download the dataset file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_series : pd.Series\n",
    "        A row from the dataset DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataset : str\n",
    "       The dataset filename\n",
    "    \"\"\"\n",
    "    # Need a default return value\n",
    "    dataset_filename = None\n",
    "\n",
    "    # Get the dataset object\n",
    "    collection_id = dataset_series.collection_id\n",
    "    dataset_id = dataset_series.dataset_id\n",
    "    dataset_url = f\"{CELLXGENE_API_URL_BASE}/curation/v1/collections/{collection_id}/datasets/{dataset_id}\"\n",
    "    sleep(HTTPS_SLEEP)\n",
    "    response = requests.get(dataset_url)\n",
    "    response.raise_for_status()\n",
    "    if response.status_code != 200:\n",
    "        logging.error(f\"Could not get dataset for id {dataset_id}\")\n",
    "        return\n",
    "\n",
    "    data = response.json()\n",
    "    if dataset_id != data[\"dataset_id\"]:\n",
    "        logging.error(\n",
    "            f\"Response dataset id: {data['dataset_id']} does not equal specified dataset id: {dataset_id}\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Find H5AD files, if possible\n",
    "    assets = data[\"assets\"]\n",
    "    for asset in assets:\n",
    "        if asset[\"filetype\"] != \"H5AD\":\n",
    "            continue\n",
    "\n",
    "        # Found an H5AD file, so download it, if needed\n",
    "        dataset_filename = f\"{dataset_id}.{asset['filetype']}\"\n",
    "        dataset_filepath = f\"{CELLXGENE_DIR}/{dataset_filename}\"\n",
    "        if not os.path.exists(dataset_filepath):\n",
    "            print(f\"Downloading dataset file: {dataset_filepath}\")\n",
    "            with requests.get(asset[\"url\"], stream=True) as response:\n",
    "                response.raise_for_status()\n",
    "                with open(dataset_filepath, \"wb\") as df:\n",
    "                    for chunk in response.iter_content(chunk_size=1024 * 1024):\n",
    "                        df.write(chunk)\n",
    "            print(f\"Dataset file: {dataset_filepath} downloaded\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Dataset file: {dataset_filepath} exists\")\n",
    "\n",
    "    return dataset_filename\n"
   ],
   "id": "eda7498a-8fff-4bfc-b6e1-3ac731b6330c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then call it using the first row of the human lung cell datasets\n",
    "DataFrame obtained above, and print the result (we'll use exception\n",
    "handling when accessing an external resource from now on):"
   ],
   "id": "3f43c21a-0a37-43b7-953c-90cacaec4831"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "results": "output",
    "session": "shared"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    dataset_series = lung_datasets.iloc[0]\n",
    "    get_and_download_dataset_h5ad_file(dataset_series)\n",
    "except Exception:\n",
    "    print_exc()\n"
   ],
   "id": "fe5e7cf3-10e7-46b4-a529-2de7a93c2d30"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, in [Chapter-02-E-Utilities.ipynb](Chapter-02-E-Utilities.ipynb),\n",
    "we write functions to search PubMed for the title and identifiers."
   ],
   "id": "22730659-e404-47a1-906a-62c98f95f53a"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
